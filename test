  docker compose logs -f chainreactions-app

    docker compose build --no-cache
      docker compose up -d

        docker compose down


        docker compose logs -f chainreactions-app




cd /home/chainreactions/app
git pull origin main
docker compose down
docker compose build --no-cache
docker compose up -d
docker compose logs -f chainreactions-app

  docker compose down --remove-orphans


  docker compose ps

  docker compose logs --tail=50 chainreactions-app




  # =================================================================
# GEMINI OSINT SEARCH API - ENVIRONMENT CONFIGURATION
# =================================================================

# =====================
# CORE API KEYS
# =====================
# Google Gemini API Configuration
GEMINI_API_KEY=AIzaSyB81s_gXvl61v-81_-mlKU0TnrwK8m8qEc

# =====================
# BRIGHT DATA SERP API (Primary Multi-Engine Search)
# =====================
# Get your API key and zone from: https://brightdata.com/cp/zones
# Supports: Google, Bing, Baidu, Yandex, DuckDuckGo search engines
BRIGHT_DATA_API_KEY=fab61ac190d52f493fcbc5f12e7a7a90196fd0cc8ac22156468ad5cc6370ad51
BRIGHT_DATA_SERP_ZONE=serp_api1

# =====================
# LEGACY SEARCH ENGINE API KEYS (Optional)
# =====================
# These are now optional since Bright Data SERP API provides unified access
BING_SEARCH_API_KEY=
GOOGLE_SEARCH_API_KEY=
GOOGLE_SEARCH_ENGINE_ID=
BAIDU_API_KEY=
YANDEX_API_KEY=

# =====================
# MCP TOOLS API KEYS (Planned Integration)
# =====================
# For specialized OSINT data sources
NEWS_API_KEY=
ARXIV_API_KEY=
OPENCORPORATES_API_KEY=
CRUNCHBASE_API_KEY=

# =====================
# SERVER CONFIGURATION
# =====================
PORT=3000
NODE_ENV=development

# =====================
# GEMINI MODEL SETTINGS
# =====================
GEMINI_MODEL=gemini-2.5-flash
API_TIMEOUT=300000
MAX_RETRIES=3

# =====================
# MULTI-SEARCH ENGINE SETTINGS
# =====================
DEFAULT_MAX_RESULTS_PER_ENGINE=20
DEDUPLICATION_THRESHOLD=0.8
MIN_ENGINES_FOR_HIGH_CONFIDENCE=2

# =====================
# RATE LIMITING
# =====================
REQUESTS_PER_MINUTE=60
REQUESTS_PER_HOUR=1000

# =================================================================
# ENTITY SEARCH API CONFIGURATION (Integrated from port 3002)
# =================================================================
LINKUP_API_KEY=00ebe384-1321-47b2-b963-adaa2cc696dc
LINKUP_BASE_URL=https://api.linkup.so/v1

# =================================================================
# DATASET MATCHING CONFIGURATION (Integrated from port 3003)
# =================================================================
# Supabase Configuration
SUPABASE_URL=https://keacwlgxmxhbzskiximn.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImtlYWN3bGd4bXhoYnpza2l4aW1uIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTg4NTc4NzgsImV4cCI6MjA3NDQzMzg3OH0.0vVyepn845skGQPUsaxRurAuLzUNiO6oGMQeBbJiEb4
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImtlYWN3bGd4bXhoYnpza2l4aW1uIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTcyNzYzOTY2NCwiZXhwIjoyMDQzMjE1NjY0fQ.I7m4R5TgKH_gGzKTYJZOQkHYa8rG47nNqC3SHFp4JQ

# Redis Configuration (Optional for caching)
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=
REDIS_DB=0

# Dataset Matching Configuration
DEFAULT_MIN_CONFIDENCE=0.6
CACHE_EXPIRATION_MINUTES=5
ENABLE_DISTRIBUTED_CACHE=false
BATCH_SIZE_LIMIT=100

# Dataset Matching Logging Configuration
LOG_LEVEL=info
ENABLE_REQUEST_LOGGING=true

# =================================================================
# DATASET SEARCH CONFIGURATION (Integrated from port 3004)
# =================================================================
# Second Linkup API Key for Dual Processing
LINKUP_API_KEY_2=1f1e5ae1-b43f-49b2-afb1-47f07a3d2f31

# Dataset Search Configuration
DATASET_SEARCH_MAX_CONCURRENT=2
DATASET_SEARCH_TIMEOUT_MS=600000

# =================================================================
# DATA MANAGEMENT CONFIGURATION (Integrated from port 3006)
# =================================================================
# File Upload Configuration
UPLOAD_PATH=./uploads
MAX_FILE_SIZE=50MB
ALLOWED_FILE_TYPES=csv,xml,json,js

# CSV Processing Configuration
CSV_IMPORT_BATCH_SIZE=1000
CSV_IMPORT_MAX_EMPTY_ROWS=10

# =================================================================
# DEMO EMAIL SERVICE CONFIGURATION (Integrated from port 3001)
# =================================================================
# Gmail SMTP Configuration for Demo Requests
GMAIL_APP_PASSWORD=jtie nvaf pawu tyuk
GMAIL_USER=kanbeiyan@gmail.com


  docker compose exec chainreactions-app printenv NODE_ENV
docker compose exec chainreactions-app cat /app/dist/app.js | grep -A 5 "chainreactions.site"