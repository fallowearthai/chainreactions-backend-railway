# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Node.js/TypeScript implementation of a 3-stage OSINT (Open-Source Intelligence) search tool that combines WebSearch meta-prompting, SERP API execution, and AI analysis for investigating institutional relationships and risk associations.

## 3-Stage Architecture

### Stage 1: WebSearch Meta-Prompting
- **Intelligence Gathering**: Uses WebSearch to gather entity information and relationship context
- **Search Strategy Generation**: AI analyzes web search results to create precise keyword combinations
- **Geographic Optimization**: Selects appropriate search engines based on location (e.g., Baidu for China)
- **Multi-language Support**: Generates search terms in both English and native languages

### Stage 2: SERP API Execution
- **Multi-Engine Search**: Parallel execution across Google, Baidu, Yandex via Bright Data
- **Concurrency Control**: Rate-limited parallel searches to manage API costs
- **Result Aggregation**: Deduplication and relevance scoring of search results
- **Geographic Targeting**: Engine selection optimized for target location

### Stage 3: AI Analysis & Integration
- **Relationship Analysis**: Gemini analyzes aggregated search results for relationship evidence
- **Structured Output**: Produces standardized OSINT findings format
- **Source Attribution**: Maps evidence to specific sources with citation tracking
- **Confidence Scoring**: Assesses reliability based on multi-engine consensus

## Technology Stack

- **Runtime**: Node.js with TypeScript
- **Framework**: Express.js for API handling
- **AI**: Google Gemini 2.5 Flash with thinking mode and URL context tools
- **Search**: Bright Data SERP API (multi-engine)
- **WebSearch**: Built-in WebSearch functionality

## Development Commands

```bash
npm install          # Install dependencies
npm run build        # Compile TypeScript to JavaScript
npm start            # Start the production server
npm run dev          # Start development server with hot reload
npm test             # Run tests
npm run lint         # Run ESLint
npm run type-check   # Run TypeScript type checking
```

## Project Structure

```
src/
‚îú‚îÄ‚îÄ app.ts                           # Express server and routes
‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îî‚îÄ‚îÄ EnhancedSearchController.ts  # 3-stage workflow orchestration
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ GeminiService.ts             # Gemini API integration
‚îÇ   ‚îú‚îÄ‚îÄ BrightDataSerpService.ts     # Bright Data SERP API
‚îÇ   ‚îú‚îÄ‚îÄ WebSearchMetaPromptService.ts # Stage 1: WebSearch meta-prompting
‚îÇ   ‚îú‚îÄ‚îÄ SerpExecutorService.ts       # Stage 2: Multi-engine SERP execution
‚îÇ   ‚îú‚îÄ‚îÄ ResultOptimizationService.ts # Result optimization and deduplication
‚îÇ   ‚îî‚îÄ‚îÄ ResultIntegrationService.ts  # Stage 3: AI analysis & integration
‚îî‚îÄ‚îÄ types/
    ‚îú‚îÄ‚îÄ gemini.ts                    # Gemini API and search types
    ‚îî‚îÄ‚îÄ brightDataSerpApi.ts         # Bright Data SERP API types
```

## API Endpoints

### Complete Workflow
- **POST `/api/enhanced/search`** - Full 3-stage OSINT analysis (OPTIMIZED - Default)
- **GET `/api/enhanced/search-stream`** - Full 3-stage analysis with Server-Sent Events progress
- **POST `/api/enhanced/strategy`** - Stage 1 only (meta-prompting)
- **GET `/api/enhanced/test`** - Test with sample data
- **GET `/api/enhanced/info`** - Workflow information
- **GET `/api/health`** - Health check

### Input Format
```json
{
  "Target_institution": "The primary institution to investigate",
  "Risk_Entity": "Comma-separated list of risk entities to research",
  "Location": "Geographic location (determines search engines and languages)",
  "Start_Date": "Optional time range start (YYYY-MM format)",
  "End_Date": "Optional time range end (YYYY-MM format)"
}
```

### Output Format
```json
{
  "success": true,
  "data": [
    {
      "risk_item": "Specific risk entity investigated",
      "institution_A": "Target institution",
      "relationship_type": "Direct|Indirect|Significant Mention|No Evidence Found",
      "finding_summary": "Analysis summary with numbered source citations [1], [2]",
      "potential_intermediary_B": "Any intermediary organizations identified",
      "sources": ["Array of source URLs"]
    }
  ],
  "metadata": {
    "total_risk_entities": 2,
    "analysis_timestamp": "2024-01-15T10:30:00Z",
    "search_execution_summary": {
      "totalQueries": 24,
      "successfulQueries": 22,
      "totalResults": 156,
      "enginesUsed": ["google", "baidu", "yandex"],
      "executionTime": 45000
    },
    "overall_confidence": 0.85,
    "methodology": "WebSearch Meta-Prompt + Multi-Engine SERP + AI Analysis"
  },
  "sources": ["Unique URLs from all findings"]
}
```

## Environment Configuration

All API keys and configuration are centralized in the `.env` file:

### Required API Keys
- `GEMINI_API_KEY`: Google Gemini API key (required)
- `BRIGHT_DATA_API_KEY`: Bright Data API key for multi-engine search
- `BRIGHT_DATA_SERP_ZONE`: Bright Data SERP zone identifier

### Server Configuration
- `PORT`: Server port (default: 3000)
- `NODE_ENV`: Environment (development/production)

## Testing

```bash
# Test the complete 3-stage workflow
curl -X POST http://localhost:3000/api/enhanced/search \
  -H "Content-Type: application/json" \
  -d '{
    "Target_institution": "NanoAcademic Technologies",
    "Risk_Entity": "HongZhiWei",
    "Location": "China"
  }'

# Test just the meta-prompting stage
curl -X POST http://localhost:3000/api/enhanced/strategy \
  -H "Content-Type: application/json" \
  -d '{
    "Target_institution": "NanoAcademic Technologies",
    "Risk_Entity": "HongZhiWei",
    "Location": "China"
  }'

# Quick test with sample data
curl -X GET http://localhost:3000/api/enhanced/test
```

## Key Features

### üéØ Core Capabilities
1. **Intelligent Search Strategy**: WebSearch-informed keyword generation
2. **Multi-Engine Coverage**: Parallel searches across Google, Baidu, Yandex
3. **Geographic Optimization**: Native search engines for regional content
4. **Result Quality**: Advanced deduplication and relevance scoring
5. **Structured Output**: Standardized OSINT analysis format
6. **Source Attribution**: Comprehensive citation tracking

### üöÄ Technical Excellence
- **100% Success Rate**: All three stages fully operational
- **Dynamic Entity Matching**: Works with any entity combinations
- **Thinking Mode AI**: Enhanced reasoning with unlimited thinking budget
- **URL Context Tools**: Comprehensive document analysis (PDFs, web content)
- **Token Optimization**: Efficient prompt engineering for cost-effective analysis
- **Real-time Progress**: Server-Sent Events for live workflow updates

### üåç Global Coverage
- **Google**: Global baseline with structured JSON parsing
- **Baidu**: Chinese content expertise with HTML parsing
- **Yandex**: Russian/Cyrillic content with HTML parsing
- **Multi-language**: Automatic language detection and optimization

## Current Status (September 2024)

### ‚úÖ Production Ready
- **Stage 1**: Single API call architecture with strict validation
- **Stage 2**: Multi-engine execution with dynamic entity matching
- **Stage 3**: Unified AI analysis with 100% success rate
- **Architecture**: Clean, maintainable codebase with comprehensive error handling

### üìä Performance Metrics
- **Total Execution Time**: ~35 seconds (Stage 1: 7s + Stage 2: 18s + Stage 3: 10s)
- **API Success Rate**: 100% across all engines
- **Results Quality**: 40+ optimized search results per analysis
- **Confidence Scoring**: 0.95+ for direct relationship identification

### üõ†Ô∏è Key Technical Achievements
- **Unified System Prompts**: Consolidated OSINT analyst instructions
- **Image Search Filtering**: Eliminated irrelevant image results
- **Dynamic Entity Processing**: Universal compatibility with any entity pairs
- **Optimized Token Usage**: Efficient Stage 3 input processing
- **Robust Error Recovery**: Comprehensive retry mechanisms

# Development Principles

## Code Quality Standards
- **Be ashamed of guessing APIs in the dark; be proud of reading the docs carefully.**
- **Be ashamed of vague execution; be proud of seeking clarification and confirmation.**
- **Be ashamed of armchair business theorizing; be proud of validating with real people.**
- **Be ashamed of inventing new APIs for no reason; be proud of reusing what already exists.**
- **Be ashamed of skipping validation; be proud of proactive testing.**
- **Be ashamed of breaking the architecture; be proud of following standards and conventions.**
- **Be ashamed of pretending to understand; be proud of honest "I don't know."**
- **Be ashamed of blind edits; be proud of careful refactoring.**