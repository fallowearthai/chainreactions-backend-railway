# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

ChainReactions Backend is a microservices architecture implementing OSINT (Open-Source Intelligence) capabilities through independent Node.js/TypeScript services. The project follows a modular approach where each feature is developed as a separate service before being integrated into a unified API gateway.

## Architecture

### Microservices Design
The project consists of independent services running on separate ports:

1. **Entity Relations Service** (Port 3000) - **Unified OSINT Platform**
   - **Integrated Services**: Entity Search, Dataset Matching, DeepThinking & Normal Search modes
   - DeepThinking Mode: 3-stage workflow with multi-engine SERP
   - Normal Search Mode: Fast Google Web Search analysis
2. **Demo Request Email Service** (Port 3001) - Email handling service
3. **Dataset Search Service** (Port 3004) - Dataset search with dual Linkup API integration
4. **Data Management Service** (Port 3006) - CSV upload and intelligent parsing service

### Integrated Services (Legacy)
The following services have been fully integrated into the Entity Relations Service (Port 3000):
- ~~Entity Search Service~~ (Port 3002) - Now integrated as `entity-search` module
- ~~Dataset Matching Service~~ (Port 3003) - Now integrated as `dataset-matching` module

### Common Technology Stack
- **Runtime**: Node.js with TypeScript
- **Framework**: Express.js for REST APIs
- **Development**: Nodemon with ts-node for hot reload
- **Build**: TypeScript compiler (`tsc`)
- **Testing**: Jest framework

## Development Commands

Each service follows the same command structure:

```bash
# Development
npm install          # Install dependencies
npm run dev          # Start development server with hot reload
npm run build        # Compile TypeScript to JavaScript
npm start            # Start production server
npm test             # Run Jest tests
npm run test:watch   # Run tests in watch mode
npm run lint         # Run ESLint
npm run type-check   # Run TypeScript type checking without compilation
```

## üîí Port Configuration Rules (CRITICAL)

**FIXED PORT ALLOCATION - DO NOT CHANGE**:
- **Frontend**: `8080` (STRICT - no auto-increment allowed)
- **Entity Relations Service**: `3000` (Unified OSINT Platform - includes Entity Search & Dataset Matching)
- **Demo Email Service**: `3001`
- **Dataset Search Service**: `3004`
- **Data Management Service**: `3006`

**DEPRECATED PORTS** (No longer in use - services integrated into Port 3000):
- ~~Port 3002~~ - Entity Search Service (integrated into Port 3000)
- ~~Port 3003~~ - Dataset Matching Service (integrated into Port 3000)

**Port Conflict Resolution**:
```bash
# Check port status
lsof -i :PORT_NUMBER

# Kill process occupying port
kill PID_NUMBER

# Always start services in order: Backend services first, then frontend
```

**CORS Configuration**: All backend services MUST allow `http://localhost:8080` origin
**Testing Ports**: Use range `9000-9999` to avoid conflicts with production ports

### Service-Specific Directories
- `entity_relations_deepthinking/` - **Unified OSINT Platform** (Port 3000)
  - **Core**: DeepThinking & Normal Search modes
  - **Integrated**: Entity Search (`src/services/entity-search/`) and Dataset Matching (`src/services/dataset-matching/`)
  - **Complete**: All OSINT capabilities unified in single service
- `demo_email/` - Email service for demo requests (Port 3001)
- `dataset_search/` - Dataset search with dual Linkup API integration (Port 3004)
- `data_management/` - CSV upload and intelligent parsing service (Port 3006)

### Removed Directories (Fully Integrated)
The following directories have been completely removed as their functionality is now integrated into the unified Entity Relations Service:
- ~~`entity_search/`~~ - Integrated as `entity_relations_deepthinking/src/services/entity-search/`
- ~~`dataset_matching/`~~ - Integrated as `entity_relations_deepthinking/src/services/dataset-matching/`

## Key Services Documentation

### Entity Relations Service (Unified Dual-Mode OSINT)
**Unified Service** running on Port 3000 with two operational modes:

#### Mode 1: DeepThinking (3-Stage Workflow)
Comprehensive OSINT analysis with multi-engine search:

1. **Stage 1**: WebSearch Meta-Prompting for intelligent search strategy
2. **Stage 2**: Multi-engine SERP execution (Google, Baidu, Yandex)
3. **Stage 3**: AI analysis and relationship integration

**Key Features**:
- Google Gemini 2.5 Flash integration with thinking mode
- Bright Data SERP API for multi-engine search
- Geographic engine optimization
- Server-Sent Events (SSE) for real-time progress
- Processing time: ~35-60 seconds
- Endpoint: `POST /api/enhanced/search`

#### Mode 2: Normal Search (Google Web Search)
Simplified OSINT analysis with Google Web Search:

- **Single-Stage Workflow**: Direct Gemini API call with googleSearch tool
- **Fast Processing**: 10-30 seconds typical response time
- **Google Web Search**: Native integration via Gemini's googleSearch capability
- **Multi-language**: Automatic search in English and native language of Location
- **Time Range Support**: Optional date filtering using Google search operators
- **N8N Compatible**: Drop-in replacement for existing N8N webhook
- **Endpoint**: `POST /api/normal-search`

**Critical Implementation Notes**:
- Both modes share Port 3000 for unified frontend integration
- Contains extensive CLAUDE.md with detailed architecture
- JSON parsing includes multi-layered fallback strategies
- Never modify AI system prompts without explicit permission
- Includes intelligent search engine normalization

### Entity Search Service
**[INTEGRATED INTO Port 3000]** Linkup API integration for professional business intelligence:

#### Core Features
- Intelligent domain filtering (excludes 12+ low-quality sources)
- Custom exclude_domains parameter support
- Multi-strategy JSON parsing with 4 fallback mechanisms
- **Default Domain Filtering**: Automatically excludes low-quality sources:
  - `wikipedia.org` - Áª¥Âü∫ÁôæÁßë
  - `reddit.com` - RedditËÆ∫Âùõ
  - `quora.com` - QuoraÈóÆÁ≠î
  - `pinterest.com` - Pinterest
  - Social media platforms: `twitter.com`, `facebook.com`, `instagram.com`, `youtube.com`
  - Other: `wiki.fandom.com`, `wikimedia.org`, `tiktok.com`, `snapchat.com`

#### API Usage
```bash
# Standalone testing (integrated into Port 3000 for production)
curl -X POST http://localhost:3002/api/entity-search \
  -H "Content-Type: application/json" \
  -d '{
    "company_name": "Apple Inc.",
    "location": "United States",
    "exclude_domains": ["wikipedia.org", "reddit.com"]
  }'
```

#### Performance & Troubleshooting
- **Expected Response Time**: 30-35 seconds
- **Debug Mode**: Set `NODE_ENV=development` for detailed logging
- **Common Issues**:
  - Linkup API connection failures: Check API key and network connectivity
  - Port conflicts: Ensure port 3002 is available
  - JSON parsing failures: Review service logs for parsing errors
- **Health Check**: `curl http://localhost:3002/api/health`

### Dataset Matching Service
**[INTEGRATED INTO Port 3000]** Advanced entity matching with multiple algorithms:

#### Core Features
- **Multi-Algorithm Matching**: Jaro-Winkler, Levenshtein, N-gram similarity algorithms
- **Quality Assessment**: Intelligent scoring to reduce false positives
- **8 Match Types**: exact, alias, alias_partial, fuzzy, partial, core_match, core_acronym, word_match
- **Memory Caching**: 5-minute expiry for performance optimization
- **Batch Processing**: Support up to 100 entities per request
- **Intelligent Bracket Processing**: Handles entity names with acronyms (e.g., "National University of Defense Technology (NUDT)")
- **Geographic Matching**: Regional boosting algorithms
- **Configurable Parameters**: Similarity thresholds and algorithm weights

#### Performance Characteristics
- **Expected Performance**:
  - Single Match: < 50ms average response time
  - Batch Match (10 entities): < 200ms average response time
  - Cache Hit Ratio: 90%+ for repeated queries
  - Concurrent Requests: Supports 100+ concurrent requests
- **Optimization Features**:
  - Multi-level caching (memory + Redis)
  - Batch processing with parallel execution
  - Database connection pooling
  - Response compression
  - Query optimization

#### API Usage
```bash
# Standalone testing (integrated into Port 3000 for production)
curl -X POST http://localhost:3003/api/dataset-matching/match \
  -H "Content-Type: application/json" \
  -d '{
    "entity": "Apple Inc",
    "minConfidence": 0.7,
    "matchTypes": ["exact", "alias", "fuzzy"]
  }'

# Batch match
curl -X POST http://localhost:3003/api/dataset-matching/batch \
  -H "Content-Type: application/json" \
  -d '{
    "entities": ["Tesla Inc", "Microsoft", "Apple"],
    "options": {
      "minConfidence": 0.6,
      "forceRefresh": false
    }
  }'
```

#### Algorithm Details
- **Text Normalization**: Removes parentheses and organizational suffixes, standardizes spacing
- **Quality Assessment**:
  - Generic Term Detection: Filters common words
  - Length Validation: Ensures reasonable proportions
  - Context Scoring: Improves accuracy based on usage
  - Confidence Calibration: Dynamic threshold adjustment
- **Fuzzy Matching**: Levenshtein distance, Jaro-Winkler similarity, N-gram analysis, Phonetic matching

#### Troubleshooting
- **Debug Mode**: Set `NODE_ENV=development` for detailed logging including request/response logging, algorithm performance metrics, cache hit/miss statistics
- **Common Issues**:
  - Supabase Connection Fails: Verify `SUPABASE_URL` and `SUPABASE_ANON_KEY` in `.env`
  - Low Match Quality: Adjust `DEFAULT_MIN_CONFIDENCE` threshold, check dataset quality
  - Performance Issues: Enable Redis caching, increase `CACHE_EXPIRATION_MINUTES`
- **Health Check**: `curl http://localhost:3003/api/health`

### Data Management Service
CSV upload and intelligent parsing with Supabase integration:
- Smart CSV parser with automatic field mapping
- Support for multiple CSV formats with high adaptability
- Priority field detection: organization_name, aliases, countries
- Metadata preservation for unmapped fields
- Supabase database integration with dataset_entries table
- Real-time upload progress and validation

### Demo Email Service
Gmail SMTP integration for demo request handling:
- Nodemailer integration
- HTML email templates
- Form validation and error handling

### Dataset Search Service
Advanced OSINT relationship search with dual API parallel processing:
- **Dual Linkup API Integration**: True parallel processing with 2 API keys using round-robin distribution
- **Server-Sent Events (SSE)**: Real-time streaming of search progress and results
- **Canadian NRO Database**: Integration with Supabase for 103 Canadian organizations
- **Performance Optimization**: 84% speed improvement (164s ‚Üí 27s for 6 entities)
- **Enhanced Rate Limiting**: Individual rate limiters per API key (10 queries/second each)
- **Intelligent Response Parsing**: Multi-layered JSON parsing with fallback strategies
- **Real-time API Status**: Frontend displays which API processes each entity
- **CORS Support**: Configured for both local file testing and frontend server integration
- **Search Configuration**: Standard depth search with OSINT-optimized prompts
- **Error Handling**: Comprehensive error management with API-specific logging

## Environment Configuration

Each service requires its own `.env` file with service-specific API keys:

### Common Environment Variables
```bash
PORT=3000                    # Service port
NODE_ENV=development         # Environment
```

### Service-Specific Keys
- `GEMINI_API_KEY` - Google Gemini API (Entity Relations Service - both modes)
- `BRIGHT_DATA_API_KEY` - Bright Data SERP API (Entity Relations DeepThinking mode only)
- `LINKUP_API_KEY` - Primary Linkup API (Entity Search, Dataset Search)
- `LINKUP_API_KEY_2` - Secondary Linkup API (Dataset Search Dual Processing)
- `GMAIL_APP_PASSWORD` - Gmail SMTP (Demo Email)
- `SUPABASE_URL` and `SUPABASE_ANON_KEY` - Database (Dataset Matching, Dataset Search)

## Development Workflow

### Testing Individual Services
Each service can be tested independently:

```bash
# Entity Relations Service - DeepThinking Mode (3-stage workflow)
cd entity_relations_deepthinking
curl -X POST http://localhost:3000/api/enhanced/search \
  -H "Content-Type: application/json" \
  -d '{"Target_institution": "NanoAcademic Technologies", "Risk_Entity": "HongZhiWei", "Location": "China"}'

# Entity Relations Service - Normal Search Mode (Google Web Search)
cd entity_relations_deepthinking
curl -X POST http://localhost:3000/api/normal-search \
  -H "Content-Type: application/json" \
  -d '{"Target_institution": "Apple Inc", "Risk_Entity": "Military", "Location": "United States"}'

# Entity Search
cd entity_search
curl -X POST http://localhost:3002/api/entity-search \
  -H "Content-Type: application/json" \
  -d '{"query": "Apple Inc", "exclude_domains": ["wikipedia.org"]}'

# Dataset Matching
cd dataset_matching
curl -X POST http://localhost:3003/api/dataset-matching/match \
  -H "Content-Type: application/json" \
  -d '{"entity": "Apple Inc", "match_type": "fuzzy"}'

# Dataset Search (SSE Streaming with Dual API)
cd dataset_search
curl -X POST http://localhost:3004/api/dataset-search/stream \
  -H "Content-Type: application/json" \
  -d '{"target_institution": "Apple Inc", "test_mode": true}'

# Dataset Search Health Check
curl -s http://localhost:3004/api/health | jq
```

### Service Health Checks
All services provide health check endpoints:
- `/api/health` - Basic health status
- Service-specific test endpoints available

## Project Status and Development Strategy

### Completed Modules (100%)
1. ‚úÖ **Entity Relations Service (Unified Dual-Mode)** - Port 3000
   - DeepThinking Mode: 3-stage OSINT workflow
   - Normal Search Mode: Google Web Search based OSINT
   - Shared infrastructure with dual endpoints
2. ‚úÖ Demo Request Email Service
3. ‚úÖ Entity Search Service
4. ‚úÖ Dataset Matching Service (with full entity matching pipeline including bracketed names and cache management)
5. ‚úÖ Data Management Service (CSV upload and intelligent parsing)
6. ‚úÖ Dataset Search Service (SSE streaming with Linkup API integration)

### Current Development
1. **Dataset Search Service Frontend Integration** - Complete migration from N8N to pure TypeScript
   - SSE streaming implementation ‚úÖ
   - Linkup API integration ‚úÖ
   - Canadian NRO database integration ‚úÖ
   - Frontend testing interface needs restoration

### Planned Development
1. **Unified API Gateway** - Service orchestration and routing
2. **Production Deployment** - Containerization and scaling

### Recent Achievements (Oct 10, 2025)
- üöÄ **Dataset Search Concurrent Pool Architecture**: Implemented true concurrent pool processing for stable, predictable performance
  - **Concurrent Pool Design**: Separate sequential pools per API key for true parallelism
  - **Rate Limiter Removal**: Eliminated 100ms wait per entity, removed ~10.3s overhead for 103 entities
  - **Stable Performance**: Fixed "Ë∂äÊù•Ë∂äÊÖ¢" issue - consistent speed throughout entire 103-entity search
  - **Architecture Pattern**: Pool 1 (API 1) and Pool 2 (API 2) run in parallel, each processing entities sequentially
  - **Production Ready**: Successfully tested with full 103-entity Canadian NRO dataset
  - **Code Location**: `entity_relations_deepthinking/src/services/dataset-search/services/LinkupSearchService.ts:200-437`

### Previous Achievements (Oct 4, 2025)
- üîó **Entity Relations Service Unification**: Merged DeepThinking and Normal Search into single service
  - **Unified Port 3000**: Both modes now run on same server instance
  - **Dual Endpoints**: `/api/enhanced/search` (DeepThinking) and `/api/normal-search` (Normal)
  - **Shared Infrastructure**: Common middleware, logging, and error handling
  - **Simplified Deployment**: Single service to start and manage
  - **Frontend Compatibility**: Maintains all existing API contracts

### Previous Achievements (Oct 3, 2025)
- üöÄ **Entity Relations Normal Search Service Complete**: Migrated from N8N to pure TypeScript backend
  - **Google Web Search Integration**: Direct integration via Gemini googleSearch tool
  - **Single-Call Architecture**: Simplified workflow compared to DeepThinking (10-30s vs 35-60s)
  - **Multi-language Support**: Automatic search in English and native language
  - **N8N Compatible Format**: Drop-in replacement with identical response structure
  - **Robust JSON Parsing**: Multi-layered fallback parsing strategy

### Previous Achievements (Oct 2, 2025)
- üé® **Dataset Search UI Optimization**: Enhanced frontend user experience
  - **Completion Message Update**: Changed from "Long text search completed successfully" to "Dataset Search Completed"
  - **No Results Handling**: Added "No Relationship Founded" record for searches with no findings
  - **History Auto-Update**: Implemented post-search automatic history refresh
  - **RLS Configuration**: Enabled Row Level Security on `long_text_search_history` table
  - **Optimized Update Strategy**: Replaced Realtime subscription with direct refresh after save (better for 7-10min searches)
- üîß **UI Bug Fixes**: Fixed HTML nesting warnings in `ClearAllHistoryDialog`
  - Resolved `<div>` cannot be descendant of `<p>` validation errors
  - Improved AlertDialog component structure with proper `asChild` usage

### Previous Achievements (Sept 30, 2025)
- üöÄ **Complete Dataset Search Service Implementation**: Migrated from N8N workflows to pure TypeScript with SSE streaming
- ‚ö° **Dual API Parallel Processing Optimization**: Implemented true parallel processing with 2 Linkup API keys
  - **Performance Boost**: Reduced search time from 164s to 27s (84% improvement)
  - **Parallel Execution**: Round-robin distribution across multiple API keys
  - **Enhanced Rate Limiting**: Individual rate limiters per API key
  - **Real-time API Status**: Frontend displays which API processes each entity
- üîß **Fixed Linkup API Integration**: Corrected request format from `query/outputFormat` to `q/outputType`
- ‚úÖ **Enhanced SSE Streaming**: Real-time progress updates with API allocation information
- üîó **Canadian NRO Database Integration**: Successfully processing 103 Canadian organizations in test mode
- üéØ **SSE Issues Resolution**: Fixed "undefined - undefined" events and executionId extraction
- üì° **Optimized Search Parameters**: Changed depth from "deep" to "standard" for better performance
- üîß **CORS Configuration**: Updated to support local HTML file testing alongside frontend server
- üîç **Critical JSON Response Fix**: Successfully resolved Linkup API response format issues
  - **excludeDomains Implementation**: Added domain filtering matching entity_search service success pattern
  - **Optimized OSINT Prompts**: Updated terminology (Risk Item C, risk item) and simplified JSON format requirements
  - **Structured JSON Responses**: Now consistently receiving properly parsed structured data from Linkup API
  - **High-Quality Sources**: Automatic filtering of low-quality domains (Wikipedia, Reddit, Quora, Pinterest)
  - **API Configuration Alignment**: Matched successful entity_search service parameter configuration

### Previous Achievements (Sept 28, 2025)
- üîß **Fixed Dataset Matching Critical Bug**: Resolved entity matching failure for bracketed names like "National University of Defense Technology (NUDT)"
- üîç **Enhanced Database Query Logic**: Improved acronym extraction and multi-variation searching in SupabaseService
- üöÄ **Cache Management Fix**: Identified and resolved cache invalidation issues preventing updated results
- ‚úÖ **Full Integration Testing**: Verified end-to-end functionality from frontend to database matching

### Development Philosophy
- **Modular First**: Each feature developed as independent service
- **Integration Later**: Services unified through API gateway
- **Frontend Compatibility**: Maintain existing frontend interface compatibility
- **Progressive Migration**: Gradual replacement of N8N workflows

## Critical Development Rules

### Frontend Project Location
**IMPORTANT**: The frontend project is located at `/Users/kanbei/Code/chainreactions_frontend_dev/`
- **NEVER** start services from `entity_relations_deepthinking` as frontend
- Frontend runs on port 8080+ (Vite will auto-increment if ports are busy)
- Backend data management service runs on port 3006
- Always use `cd /Users/kanbei/Code/chainreactions_frontend_dev && npm run dev` for frontend

### Entity Relations Service Rules
- **NEVER modify system prompts** without explicit user approval
- Prompts are carefully crafted for specific AI behavior and output formatting
- This includes system instructions for both DeepThinking and Normal Search modes
- Each mode has independent prompts optimized for its specific workflow

### General Code Quality
- Follow existing TypeScript conventions in each service
- Maintain consistent error handling patterns
- Preserve API response formats for frontend compatibility
- Use environment variables for all external service configuration

## Testing and Quality Assurance

### Service Testing
- Each service includes comprehensive Jest test setup
- Health check endpoints for service validation
- API endpoint testing with sample data

### Type Safety
- Full TypeScript implementation across all services
- Type checking via `npm run type-check`
- Interface definitions in dedicated `types/` directories

### Code Quality
- ESLint configuration for consistent code style
- Automated linting via `npm run lint`

## SaaSÊû∂ÊûÑÊºîËøõÁ≠ñÁï•

### üéØ **ÊàòÁï•ÂÜ≥Á≠ñÔºöÂÖàËøÅÁßªÈÉ®ÁΩ≤ÔºåÂêéSaaSÈáçÊûÑ**

ÁªèËøáÊ∑±ÂÖ•ÂàÜÊûêÔºåÊàë‰ª¨ÈááÁî®Ê∏êËøõÂºèÊû∂ÊûÑÊºîËøõÁ≠ñÁï•Ôºö**‰ºòÂÖàÂÆåÊàêÁîü‰∫ßËøÅÁßªÂíåÈÉ®ÁΩ≤ÔºåÁ®≥ÂÆöÂêéÂÜçËøõË°åSaaSÁ∫ßÊû∂ÊûÑÈáçÊûÑ**„ÄÇ

### üìä **ÂΩìÂâçÊû∂ÊûÑËØÑ‰º∞**

#### ‚úÖ **Áé∞Êúâ‰ºòÂäø**
- **Áªü‰∏ÄAPIÂÖ•Âè£**ÔºöPort 3000Áªü‰∏ÄÂØπÂ§ñÔºåÁ¨¶ÂêàÁé∞‰ª£SaaSÊúÄ‰Ω≥ÂÆûË∑µ
- **ÂäüËÉΩÂÆåÊï¥ÊÄß**ÔºöÊâÄÊúâÊúçÂä°Ê≠£Â∏∏ËøêË°åÔºåÂâçÁ´ØÈõÜÊàêËâØÂ•Ω
- **APIÂÖºÂÆπÊÄß**Ôºö‰øùÊåÅÁ®≥ÂÆöÁöÑÊé•Âè£Â•ëÁ∫¶ÔºåÊó†Á†¥ÂùèÊÄßÂèòÊõ¥
- **ËøêÁª¥ÁÆÄÊ¥ÅÊÄß**ÔºöÂçï‰ΩìÁªìÊûÑÔºåÈÉ®ÁΩ≤ÂíåÁõëÊéßÁõ∏ÂØπÁÆÄÂçï

#### ‚ö†Ô∏è **ÂæÖÊîπËøõÊñπÈù¢**
- **ÂÜÖÈÉ®ÊúçÂä°ËÄ¶Âêà**Ôºö43‰∏™ÊúçÂä°Êñá‰ª∂Ê∑∑ÊùÇÔºåÁº∫‰πèÊ∏ÖÊô∞ÁöÑ‰∏öÂä°ËæπÁïå
- **Áº∫‰πè‰ºÅ‰∏öÁ∫ßÂü∫Á°ÄËÆæÊñΩ**ÔºöËÆ§ËØÅÊéàÊùÉ„ÄÅÈôêÊµÅÁÜîÊñ≠„ÄÅÁªìÊûÑÂåñÊó•ÂøóÁ≠â
- **ÂèØÊâ©Â±ïÊÄßÈôêÂà∂**ÔºöÂçï‰ΩìÊû∂ÊûÑÔºåÈöæ‰ª•Áã¨Á´ãÊâ©Â±ïÂíåÈÉ®ÁΩ≤
- **Êï∞ÊçÆÂ∫ìËÆæËÆ°**ÔºöÁº∫‰πèÊï∞ÊçÆËÆøÈóÆÂ±ÇÂíå‰∫ãÂä°ÁÆ°ÁêÜ

### üó∫Ô∏è **ÊºîËøõË∑ØÁ∫øÂõæ**

#### **Phase 1: Á®≥ÂÆöÈÉ®ÁΩ≤ (ÂΩìÂâç‰ºòÂÖàÁ∫ß - 2Âë®)**
```
Week 1-2: Áîü‰∫ßÂ∞±Áª™
‚îú‚îÄ‚îÄ ÁéØÂ¢ÉÈÖçÁΩÆÂÆåÂñÑ
‚îÇ   ‚îú‚îÄ‚îÄ Áîü‰∫ßÁéØÂ¢É .env ÈÖçÁΩÆ
‚îÇ   ‚îú‚îÄ‚îÄ Êï∞ÊçÆÂ∫ìËøûÊé•‰ºòÂåñ
‚îÇ   ‚îî‚îÄ‚îÄ CORS ÂíåÂÆâÂÖ®ËÆæÁΩÆ
‚îú‚îÄ‚îÄ Âü∫Á°ÄÈÉ®ÁΩ≤ËÉΩÂäõ
‚îÇ   ‚îú‚îÄ‚îÄ Docker ÂÆπÂô®Âåñ
‚îÇ   ‚îú‚îÄ‚îÄ PM2 ËøõÁ®ãÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ ÂèçÂêë‰ª£ÁêÜÈÖçÁΩÆ
‚îú‚îÄ‚îÄ ÁõëÊéßÂíåÊó•Âøó
‚îÇ   ‚îú‚îÄ‚îÄ ÁªìÊûÑÂåñÊó•ÂøóÂü∫Á°Ä
‚îÇ   ‚îú‚îÄ‚îÄ ÂÅ•Â∫∑Ê£ÄÊü•Â¢ûÂº∫
‚îÇ   ‚îî‚îÄ‚îÄ ÈîôËØØËøΩË∏™Á≥ªÁªü
‚îî‚îÄ‚îÄ ÈÉ®ÁΩ≤È™åËØÅ
    ‚îú‚îÄ‚îÄ API ÂäüËÉΩÂÆåÊï¥ÊÄßÊµãËØï
    ‚îú‚îÄ‚îÄ ÂâçÁ´ØÈõÜÊàêÈ™åËØÅ
    ‚îî‚îÄ‚îÄ ÊÄßËÉΩÂü∫ÂáÜÂª∫Á´ã
```

**ÂÖ≥ÈîÆÁõÆÊ†á**ÔºöÁ°Æ‰øùÊúâÁ®≥ÂÆöÂèØÁî®ÁöÑÁîü‰∫ßÁéØÂ¢ÉÔºå‰∏∫ÂêéÁª≠ÈáçÊûÑÂ•†ÂÆöÂü∫Á°Ä„ÄÇ

#### **Phase 2: SaaSÊû∂ÊûÑÈáçÊûÑ (ÈÉ®ÁΩ≤ÂÆåÊàêÂêé - 4-6Âë®)**
```
Week 3-8: ‰ºÅ‰∏öÁ∫ßÊû∂ÊûÑ
‚îú‚îÄ‚îÄ ÂÜÖÈÉ®ÂæÆÊúçÂä°Âåñ
‚îÇ   ‚îú‚îÄ‚îÄ ÊúçÂä°ÊãÜÂàÜÔºöEntity Relations, Entity Search, Dataset MatchingÁ≠â
‚îÇ   ‚îú‚îÄ‚îÄ ÂÜÖÈÉ®Á´ØÂè£ÂàÜÈÖçÔºö3001-3005
‚îÇ   ‚îú‚îÄ‚îÄ ÊúçÂä°Èó¥ÈÄö‰ø°Êú∫Âà∂
‚îÇ   ‚îî‚îÄ‚îÄ Êï∞ÊçÆËÆøÈóÆÂ±ÇÂÆûÁé∞
‚îú‚îÄ‚îÄ APIÁΩëÂÖ≥ÂÆûÁé∞
‚îÇ   ‚îú‚îÄ‚îÄ Áªü‰∏ÄÂÖ•Âè£Ôºö‰øùÊåÅPort 3000ÂØπÂ§ñ
‚îÇ   ‚îú‚îÄ‚îÄ ËØ∑Ê±ÇË∑ØÁî±ÂíåË¥üËΩΩÂùáË°°
‚îÇ   ‚îú‚îÄ‚îÄ ËÆ§ËØÅÊéàÊùÉÁ≥ªÁªü
‚îÇ   ‚îî‚îÄ‚îÄ ÈôêÊµÅÁÜîÊñ≠Êú∫Âà∂
‚îú‚îÄ‚îÄ ‰ºÅ‰∏öÁ∫ß‰∏≠Èó¥‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ JWTËÆ§ËØÅÂíåRBACÊùÉÈôêÊéßÂà∂
‚îÇ   ‚îú‚îÄ‚îÄ ÁªìÊûÑÂåñÊó•Âøó(Winston)
‚îÇ   ‚îú‚îÄ‚îÄ ÁºìÂ≠òÂ±Ç(Redis)
‚îÇ   ‚îî‚îÄ‚îÄ ÂºÇÊ≠•‰ªªÂä°ÈòüÂàó(Bull Queue)
‚îî‚îÄ‚îÄ ÂèØËßÇÊµãÊÄß
    ‚îú‚îÄ‚îÄ ÊÄßËÉΩÁõëÊéßÊåáÊ†á
    ‚îú‚îÄ‚îÄ ÂàÜÂ∏ÉÂºèËøΩË∏™
    ‚îî‚îÄ‚îÄ ÂÅ•Â∫∑Áä∂ÊÄÅÊ£ÄÊü•
```

**Êû∂ÊûÑÁõÆÊ†á**ÔºöÂØπÂ§ñÂçïÁ´ØÂè£ + ÂØπÂÜÖÂæÆÊúçÂä°ÁöÑÁé∞‰ª£SaaSÊû∂ÊûÑ„ÄÇ

#### **Phase 3: ÊåÅÁª≠‰ºòÂåñ (ÈïøÊúü)**
```
Week 9+: Áîü‰∫ßÂ¢ûÂº∫
‚îú‚îÄ‚îÄ ÊÄßËÉΩ‰ºòÂåñ
‚îÇ   ‚îú‚îÄ‚îÄ Êü•ËØ¢‰ºòÂåñ
‚îÇ   ‚îú‚îÄ‚îÄ ÁºìÂ≠òÁ≠ñÁï•
‚îÇ   ‚îî‚îÄ‚îÄ Êï∞ÊçÆÂ∫ìÁ¥¢Âºï‰ºòÂåñ
‚îú‚îÄ‚îÄ ËøêÁª¥Ëá™Âä®Âåñ
‚îÇ   ‚îú‚îÄ‚îÄ CI/CDÊµÅÊ∞¥Á∫ø
‚îÇ   ‚îú‚îÄ‚îÄ Ëá™Âä®ÂåñÊµãËØï
‚îÇ   ‚îî‚îÄ‚îÄ ÂÆπÂô®ÁºñÊéí(Kubernetes)
‚îî‚îÄ‚îÄ ÂÆâÂÖ®Âä†Âõ∫
    ‚îú‚îÄ‚îÄ ÂÆâÂÖ®Êâ´Êèè
    ‚îú‚îÄ‚îÄ ÊºèÊ¥ûÁÆ°ÁêÜ
    ‚îî‚îÄ‚îÄ ÂêàËßÑÊÄßÊ£ÄÊü•
```

### üîß **ÊäÄÊúØÊû∂ÊûÑÁõÆÊ†á**

#### **ÁõÆÊ†áÊû∂ÊûÑÊ®°Âºè**
```
Frontend (Port 8080)
    ‚Üì
Load Balancer (Port 443/80)
    ‚Üì
API Gateway (Port 3000) - Áªü‰∏ÄÂÖ•Âè£
    ‚Üì
Internal Microservices
‚îú‚îÄ‚îÄ Entity Relations: 3001
‚îú‚îÄ‚îÄ Entity Search: 3002
‚îú‚îÄ‚îÄ Dataset Matching: 3003
‚îú‚îÄ‚îÄ Data Management: 3004
‚îî‚îÄ‚îÄ Dataset Search: 3005
```

#### **‰ºÅ‰∏öÁ∫ßÊäÄÊúØÊ†à**
- **APIÁΩëÂÖ≥**: http-proxy-middleware + express-rate-limit
- **ËÆ§ËØÅÊéàÊùÉ**: JWT + RBACÊùÉÈôêÊéßÂà∂
- **Êó•ÂøóÁ≥ªÁªü**: Winston + ÁªìÊûÑÂåñÊó•Âøó
- **ÁºìÂ≠òÁ≠ñÁï•**: Redis + ÂÜÖÂ≠òÁºìÂ≠ò
- **‰ªªÂä°ÈòüÂàó**: Bull Queue + Redis
- **ÁõëÊéßÁ≥ªÁªü**: Prometheus + Grafana
- **ÂÆπÂô®Âåñ**: Docker + Kubernetes

### üí° **ÂÜ≥Á≠ñ‰æùÊçÆ**

#### **‰∏∫‰ªÄ‰πàÈÄâÊã©ÂÖàËøÅÁßªÂêéÈáçÊûÑÔºü**

1. **È£éÈô©ÊéßÂà∂**
   - ‚úÖ ‰øùÊåÅÁé∞ÊúâÂäüËÉΩÁ®≥ÂÆöÔºåÈÅøÂÖçÈáçÊûÑÂºïÂÖ•Êñ∞bug
   - ‚úÖ Âü∫‰∫éÁúüÂÆû‰ΩøÁî®ÊÉÖÂÜµ‰ºòÂåñÊû∂ÊûÑÂÜ≥Á≠ñ
   - ‚úÖ Ê∏êËøõÂºèÊîπËøõÔºåÈôç‰Ωé‰∏öÂä°‰∏≠Êñ≠È£éÈô©

2. **‰∏öÂä°‰ª∑ÂÄº**
   - ‚úÖ Â∞ΩÊó©‰∏∫Áî®Êà∑Êèê‰æõÁ®≥ÂÆöÊúçÂä°
   - ‚úÖ Âø´ÈÄüÊî∂ÈõÜÁîü‰∫ßÁéØÂ¢ÉÂèçÈ¶à
   - ‚úÖ Âü∫‰∫éÂÆûÈôÖË¥üËΩΩ‰ºòÂåñÊû∂ÊûÑ

3. **Â≠¶‰π†Êî∂Áõä**
   - ‚úÖ ÂÖà‰∫ÜËß£ÁúüÂÆûÈÉ®ÁΩ≤ÊåëÊàòÂíåÊÄßËÉΩÁì∂È¢à
   - ‚úÖ ÁßØÁ¥ØÁîü‰∫ßÁéØÂ¢ÉËøêÁª¥ÁªèÈ™å
   - ‚úÖ Âü∫‰∫éÂÆûÈôÖÊï∞ÊçÆÊåáÂØºÊû∂ÊûÑ‰ºòÂåñ

4. **ËµÑÊ∫êÊïàÁéá**
   - ‚úÖ ÈÅøÂÖçËøáÂ∫¶ËÆæËÆ°ÂíåÊó†Áî®ÂäüËÉΩ
   - ‚úÖ Á≤æÂáÜÊäïËµÑÔºåËß£ÂÜ≥ÁúüÂÆûÈóÆÈ¢ò
   - ‚úÖ Ê∏êËøõÂºèÊàêÊú¨ÊéßÂà∂

### ‚ö†Ô∏è **È£éÈô©ÁºìËß£Á≠ñÁï•**

#### **Phase 1 È£éÈô©ÊéßÂà∂**
- **ÂäüËÉΩÂõûÂΩíÈ£éÈô©**: ÂÆåÊï¥ÁöÑAPIÊµãËØïÂ•ó‰ª∂
- **ÈÉ®ÁΩ≤È£éÈô©**: ËìùÁªøÈÉ®ÁΩ≤ÂíåÂõûÊªöÊú∫Âà∂
- **ÊÄßËÉΩÈ£éÈô©**: Âª∫Á´ãÊÄßËÉΩÂü∫ÂáÜÂíåÁõëÊéß

#### **Phase 2 È£éÈô©ÊéßÂà∂**
- **Êû∂ÊûÑÂ§çÊùÇÊÄß**: ÂàÜÈò∂ÊÆµÊãÜÂàÜÔºå‰øùÊåÅÂêëÂêéÂÖºÂÆπ
- **ÊúçÂä°Èó¥ÈÄö‰ø°**: ÂÆûÁé∞ÁÜîÊñ≠Âô®ÂíåÈôçÁ∫ßÁ≠ñÁï•
- **Êï∞ÊçÆ‰∏ÄËá¥ÊÄß**: ÂàÜÂ∏ÉÂºè‰∫ãÂä°ÁÆ°ÁêÜ

### üìà **ÊàêÂäüÊåáÊ†á**

#### **Phase 1 ÊàêÂäüÊ†áÂáÜ**
- [ ] Áîü‰∫ßÁéØÂ¢ÉÁ®≥ÂÆöËøêË°å7Â§©
- [ ] ÊâÄÊúâAPIÂäüËÉΩ100%Ê≠£Â∏∏
- [ ] ÂâçÁ´ØÈõÜÊàêÊó†ÈóÆÈ¢ò
- [ ] Âü∫Á°ÄÁõëÊéßÂíåÊó•ÂøóÂÆåÂ§á

#### **Phase 2 ÊàêÂäüÊ†áÂáÜ**
- [ ] ÂÜÖÈÉ®ÊúçÂä°ÂÆåÂÖ®Ëß£ËÄ¶
- [ ] APIÁΩëÂÖ≥Á®≥ÂÆöËøêË°å
- [ ] ËÆ§ËØÅÊéàÊùÉÁ≥ªÁªüÂÆåÂñÑ
- [ ] ‰ºÅ‰∏öÁ∫ßÁõëÊéßÂ∞±Áª™

#### **ÈïøÊúüÁõÆÊ†á**
- [ ] ÊîØÊåÅÊ∞¥Âπ≥Êâ©Â±ï
- [ ] 99.9%ÊúçÂä°ÂèØÁî®ÊÄß
- [ ] ÂÆåÊï¥ÁöÑCI/CDÊµÅÊ∞¥Á∫ø
- [ ] Ëá™Âä®ÂåñËøêÁª¥ËÉΩÂäõ

### üìö **ÂºÄÂèëÊåáÂØºÂéüÂàô**

1. **ÂêëÂêéÂÖºÂÆπ‰ºòÂÖà**: ÊâÄÊúâÊû∂ÊûÑÊîπËøõÂøÖÈ°ª‰øùÊåÅAPIÂÖºÂÆπÊÄß
2. **Ê∏êËøõÂºèÊîπËøõ**: ÊØè‰∏™Èò∂ÊÆµÈÉΩË¶ÅÊúâÂèØÁî®ÁöÑÁîü‰∫ßÁéØÂ¢É
3. **Êï∞ÊçÆÈ©±Âä®ÂÜ≥Á≠ñ**: Âü∫‰∫éÁîü‰∫ßÁéØÂ¢ÉÊï∞ÊçÆÊåáÂØºÊû∂ÊûÑ‰ºòÂåñ
4. **ÂÆâÂÖ®Á¨¨‰∏Ä**: ÊØè‰∏™Èò∂ÊÆµÈÉΩË¶ÅËÄÉËôëÂÆâÂÖ®ÂΩ±Âìç

## Architecture Evolution

Âü∫‰∫éSaaSÊû∂ÊûÑÊºîËøõÁ≠ñÁï•ÔºåÈ°πÁõÆÂèëÂ±ïË∑ØÁ∫øÊõ¥Êñ∞‰∏∫Ôºö

1. **Phase 1**: ‚úÖ Independent service development
2. **Phase 2**: üöß **Production deployment and stabilization** (ÂΩìÂâçÈáçÁÇπ)
3. **Phase 3**: üéØ SaaS architecture refactoring (internal microservices)
4. **Phase 4**: üöÄ Production scaling and optimization

Ëøô‰∏™ÊºîËøõÁ≠ñÁï•Á°Æ‰øùÊàë‰ª¨Âú®‰øùÊåÅ‰∏öÂä°ËøûÁª≠ÊÄßÁöÑÂêåÊó∂ÔºåÈÄêÊ≠•ÊûÑÂª∫‰ºÅ‰∏öÁ∫ßSaaSÊû∂ÊûÑËÉΩÂäõ„ÄÇ