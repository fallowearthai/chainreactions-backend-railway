# =================================================================
# ChainReactions Backend - Docker Environment Configuration
# =================================================================
# Microservices Architecture: 5 Independent Services + Redis
# Updated: October 2025 - Phase 4 Direct Connection Architecture
# =================================================================

# =================================================================
# IMPORTANT: COPY THIS FILE TO .env BEFORE RUNNING DOCKER COMPOSE
# =================================================================
# Command: cp .env.docker.example .env
# Then edit .env with your actual API keys and credentials
# =================================================================

# =====================
# CORE API KEYS (REQUIRED)
# =====================

# Google Gemini API Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# Bright Data SERP API (Multi-Engine Search)
# Get your API key and zone from: https://brightdata.com/cp/zones
BRIGHT_DATA_API_KEY=your_bright_data_api_key_here
BRIGHT_DATA_SERP_ZONE=your_bright_data_serp_zone_here

# Linkup API Keys
# Primary key for Entity Search service
LINKUP_API_KEY=your_linkup_api_key_here
# Secondary key for Dataset Search service (dual processing)
LINKUP_API_KEY_2=your_second_linkup_api_key_here
LINKUP_BASE_URL=https://api.linkup.so/v1

# =====================
# DATABASE CONFIGURATION (REQUIRED)
# =====================

# Supabase Configuration
# Get your credentials from: https://supabase.com/dashboard/project/_/settings/api
SUPABASE_URL=your_supabase_url_here
SUPABASE_ANON_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

# =====================
# GEMINI MODEL SETTINGS
# =====================
GEMINI_MODEL=gemini-2.5-flash
API_TIMEOUT=300000
MAX_RETRIES=3

# =====================
# MULTI-SEARCH ENGINE SETTINGS
# =====================
DEFAULT_MAX_RESULTS_PER_ENGINE=20
DEDUPLICATION_THRESHOLD=0.8
MIN_ENGINES_FOR_HIGH_CONFIDENCE=2

# =====================
# RATE LIMITING
# =====================
REQUESTS_PER_MINUTE=60
REQUESTS_PER_HOUR=1000

# =====================
# LINKUP API MONITORING & CREDIT PROTECTION
# =====================
# CRITICAL: These settings prevent unexpected Linkup API credit consumption
# Set appropriate limits based on your subscription and usage patterns

# Hourly API call limit (prevents runaway consumption)
LINKUP_API_HOURLY_LIMIT=100

# Daily API call limit (prevents excessive daily usage)
LINKUP_API_DAILY_LIMIT=1000

# Feature flag: Allow health checks to call external APIs
# IMPORTANT: Keep this FALSE in production to prevent credit consumption
# Set to TRUE only for debugging purposes
ENABLE_HEALTH_CHECK_API_CALLS=false

# =====================
# DATASET SEARCH CONFIGURATION
# =====================
DATASET_SEARCH_MAX_CONCURRENT=2
DATASET_SEARCH_TIMEOUT_MS=600000

# =====================
# DATA MANAGEMENT CONFIGURATION
# =====================

# File Upload Configuration
UPLOAD_PATH=./uploads
MAX_FILE_SIZE=50MB
ALLOWED_FILE_TYPES=csv,xml,json,js

# CSV Processing Configuration
CSV_IMPORT_BATCH_SIZE=1000
CSV_IMPORT_MAX_EMPTY_ROWS=10

# =====================
# DATASET MATCHING CONFIGURATION
# =====================

# Matching Algorithm Settings
DEFAULT_MIN_CONFIDENCE=0.6
CACHE_EXPIRATION_MINUTES=5
ENABLE_DISTRIBUTED_CACHE=false
BATCH_SIZE_LIMIT=100

# Dataset Matching Logging
ENABLE_REQUEST_LOGGING=true

# =====================
# LOGGING CONFIGURATION
# =====================
# Log Level: ERROR, WARN, INFO, DEBUG, VERBOSE
# Production recommended: INFO (only errors, warnings, and important info)
# Development default: VERBOSE (all logs)
LOG_LEVEL=INFO

# =====================
# REDIS CONFIGURATION
# =====================
# Redis connection URL (automatically set in docker-compose.yml)
# No need to change these for Docker deployment
REDIS_URL=redis://redis:6379
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# =====================
# MICROSERVICES PORTS (Docker Internal)
# =====================
# These ports are exposed for each microservice
# External mapping: localhost:PORT -> container:PORT

# Entity Relations Service
ENTITY_RELATIONS_PORT=3002

# Entity Search Service
ENTITY_SEARCH_PORT=3003

# Dataset Matching Service
DATASET_MATCHING_PORT=3004

# Data Management Service
DATA_MANAGEMENT_PORT=3005

# Dataset Search Service
DATASET_SEARCH_PORT=3006

# Redis Cache Service (internal)
REDIS_PORT_EXTERNAL=6379

# =====================
# NODE ENVIRONMENT
# =====================
NODE_ENV=production

# =================================================================
# DEPLOYMENT NOTES
# =================================================================
#
# 1. All microservices run independently on their own ports
# 2. Redis is shared across all services for caching
# 3. Frontend should connect directly to each microservice:
#    - Entity Relations: http://localhost:3002
#    - Entity Search: http://localhost:3003
#    - Dataset Matching: http://localhost:3004
#    - Data Management: http://localhost:3005
#    - Dataset Search: http://localhost:3006
#
# 4. Health check endpoints:
#    - GET http://localhost:3002/api/health
#    - GET http://localhost:3003/api/health
#    - GET http://localhost:3004/api/health
#    - GET http://localhost:3005/api/health
#    - GET http://localhost:3006/api/health
#
# 5. To start all services:
#    docker-compose up -d
#
# 6. To stop all services:
#    docker-compose down
#
# 7. To rebuild and restart:
#    docker-compose up -d --build
#
# =================================================================
